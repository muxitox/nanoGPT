{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/muxitox/nanoGPT/blob/master/train_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "767a89d3a23b3e10"
  },
  {
   "metadata": {
    "id": "c362ded32e9455f6"
   },
   "cell_type": "markdown",
   "source": [
    "# Download repo"
   ],
   "id": "c362ded32e9455f6"
  },
  {
   "metadata": {
    "id": "79598a10dafcefe0",
    "outputId": "8c37e1db-b332-400b-e643-d2b35ec9ceb1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'nanoGPT'...\n",
      "remote: Enumerating objects: 765, done.\u001B[K\n",
      "remote: Counting objects: 100% (69/69), done.\u001B[K\n",
      "remote: Compressing objects: 100% (44/44), done.\u001B[K\n",
      "remote: Total 765 (delta 41), reused 42 (delta 25), pack-reused 696 (from 3)\u001B[K\n",
      "Receiving objects: 100% (765/765), 979.89 KiB | 8.10 MiB/s, done.\n",
      "Resolving deltas: 100% (430/430), done.\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "! git clone https://github.com/muxitox/nanoGPT.git"
   ],
   "id": "79598a10dafcefe0"
  },
  {
   "metadata": {
    "id": "875b1a90c5744ba6",
    "outputId": "1e4d2a38-832e-43ce-cd1f-08c184970706",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/nanoGPT\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "%cd nanoGPT"
   ],
   "id": "875b1a90c5744ba6"
  },
  {
   "metadata": {
    "id": "56a25b9636a645e0"
   },
   "cell_type": "markdown",
   "source": [
    "# Install dependencies"
   ],
   "id": "56a25b9636a645e0"
  },
  {
   "metadata": {
    "id": "8f58b2adae534efa",
    "outputId": "7daf8379-fa3e-4b02-e0f0-cb66e2b5489d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting torch==2.2.2\n",
      "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.2)\n",
      "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.6.85)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "  Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch==2.2.2)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m755.5/755.5 MB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m96.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m87.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 kB\u001B[0m \u001B[31m50.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m12.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m166.0/166.0 MB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 kB\u001B[0m \u001B[31m8.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m167.9/167.9 MB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.9/6.9 MB\u001B[0m \u001B[31m112.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m89.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m480.6/480.6 kB\u001B[0m \u001B[31m34.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m64.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m10.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m179.3/179.3 kB\u001B[0m \u001B[31m16.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m134.8/134.8 kB\u001B[0m \u001B[31m13.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.1/194.1 kB\u001B[0m \u001B[31m17.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: xxhash, triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, tiktoken, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, torch, torchvision, torchaudio, datasets\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
      "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1+cu121\n",
      "    Uninstalling torchvision-0.20.1+cu121:\n",
      "      Successfully uninstalled torchvision-0.20.1+cu121\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.5.1+cu121\n",
      "    Uninstalling torchaudio-2.5.1+cu121:\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 tiktoken-0.8.0 torch-2.2.2 torchaudio-2.2.2 torchvision-0.17.2 triton-2.2.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "! pip install torch==2.2.2 torchvision torchaudio numpy transformers datasets tiktoken wandb tqdm"
   ],
   "id": "8f58b2adae534efa"
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install fsspec==2024.10.0"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEbArQ59EWT_",
    "outputId": "a63186d5-062e-4f5f-a3a0-375c85aed8df"
   },
   "id": "eEbArQ59EWT_",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: fsspec==2024.10.0 in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare dataset"
   ],
   "metadata": {
    "id": "lr0SHRmHEDXd"
   },
   "id": "lr0SHRmHEDXd"
  },
  {
   "cell_type": "code",
   "source": [
    "! python data/shakespeare/prepare.py"
   ],
   "metadata": {
    "id": "K7BDrV2v7Qb6",
    "outputId": "b2e10956-6c9d-4f28-f6af-21ecc1b9e7b1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "K7BDrV2v7Qb6",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train has 301,966 tokens\n",
      "val has 36,059 tokens\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "id": "V-AfxdWcDaUj"
   },
   "id": "V-AfxdWcDaUj"
  },
  {
   "cell_type": "code",
   "source": "# ! python train.py config/train_shakespeare_mingpt_gpu.py",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8J_IYNzKDdjK",
    "outputId": "6d44ffc9-0b2b-4d84-d2b1-364a9936e6d9"
   },
   "id": "8J_IYNzKDdjK",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overriding config with config/train_shakespeare_mingpt_gpu.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-shakespeare-gpu'\n",
      "eval_interval = 500 # keep frequent because we'll overfit\n",
      "eval_iters = 200\n",
      "log_interval = 50 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = False # override via command line if you like\n",
      "wandb_project = 'shakespeare'\n",
      "wandb_run_name = 'mini-gpt'\n",
      "\n",
      "dataset = 'shakespeare'\n",
      "gradient_accumulation_steps = 5\n",
      "batch_size = 12\n",
      "block_size = 256 # context of up to 64 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 2\n",
      "n_head = 6\n",
      "n_embd = 384\n",
      "dropout = 0.0 # No dropout\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 10000\n",
      "lr_decay_iters = 10000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 100 # not super necessary potentially\n",
      "\n",
      "# on Colab\n",
      "device = 'cuda'  # run on cpu only\n",
      "compile = True # do not torch compile the model\n",
      "tokens per iteration will be: 15,360\n",
      "Initializing a new model from scratch\n",
      "defaulting to vocab_size of GPT-2 to 50304 (50257 rounded up for efficiency)\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "number of parameters: 22.86M\n",
      "num decayed parameter tensors: 10, with 22,953,984 parameters\n",
      "num non-decayed parameter tensors: 5, with 1,920 parameters\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "step 0: train loss 10.8397, val loss 10.8349\n",
      "iter 0: loss 10.8441, time 41245.87ms, mfu -100.00%\n",
      "iter 50: loss 5.9579, time 223.39ms, mfu 3.07%\n",
      "iter 100: loss 4.6926, time 222.95ms, mfu 3.07%\n",
      "iter 150: loss 4.4411, time 223.71ms, mfu 3.07%\n",
      "iter 200: loss 3.6750, time 224.08ms, mfu 3.07%\n",
      "iter 250: loss 3.3987, time 222.67ms, mfu 3.07%\n",
      "iter 300: loss 2.9905, time 226.76ms, mfu 3.07%\n",
      "iter 350: loss 2.5150, time 224.23ms, mfu 3.07%\n",
      "iter 400: loss 1.9808, time 232.00ms, mfu 3.06%\n",
      "iter 450: loss 1.4580, time 232.44ms, mfu 3.05%\n",
      "step 500: train loss 1.2607, val loss 6.2454\n",
      "saving checkpoint to out-shakespeare-gpu\n",
      "iter 500: loss 1.1847, time 10440.30ms, mfu 2.75%\n",
      "iter 550: loss 1.0823, time 235.17ms, mfu 2.77%\n",
      "iter 600: loss 0.8150, time 234.16ms, mfu 2.78%\n",
      "iter 650: loss 0.6092, time 237.64ms, mfu 2.79%\n",
      "iter 700: loss 0.5582, time 231.36ms, mfu 2.81%\n",
      "iter 750: loss 0.4417, time 236.77ms, mfu 2.82%\n",
      "iter 800: loss 0.3917, time 227.36ms, mfu 2.84%\n",
      "iter 850: loss 0.4136, time 229.76ms, mfu 2.86%\n",
      "iter 900: loss 0.3052, time 232.54ms, mfu 2.87%\n",
      "iter 950: loss 0.2937, time 228.24ms, mfu 2.88%\n",
      "step 1000: train loss 0.3133, val loss 7.9114\n",
      "iter 1000: loss 0.3503, time 4948.55ms, mfu 2.61%\n",
      "iter 1050: loss 0.2607, time 230.13ms, mfu 2.64%\n",
      "iter 1100: loss 0.2684, time 230.65ms, mfu 2.68%\n",
      "iter 1150: loss 0.2294, time 233.34ms, mfu 2.70%\n",
      "iter 1200: loss 0.2532, time 234.17ms, mfu 2.73%\n",
      "iter 1250: loss 0.2441, time 233.19ms, mfu 2.75%\n",
      "iter 1300: loss 0.2163, time 234.27ms, mfu 2.77%\n",
      "iter 1350: loss 0.2360, time 229.96ms, mfu 2.79%\n",
      "iter 1400: loss 0.2275, time 233.75ms, mfu 2.80%\n",
      "iter 1450: loss 0.2047, time 232.02ms, mfu 2.82%\n",
      "step 1500: train loss 0.2074, val loss 8.9221\n",
      "iter 1500: loss 0.2178, time 4900.45ms, mfu 2.55%\n",
      "iter 1550: loss 0.2234, time 231.48ms, mfu 2.59%\n",
      "iter 1600: loss 0.1762, time 229.70ms, mfu 2.63%\n",
      "iter 1650: loss 0.2159, time 230.28ms, mfu 2.67%\n",
      "iter 1700: loss 0.1952, time 233.78ms, mfu 2.69%\n",
      "iter 1750: loss 0.1828, time 229.14ms, mfu 2.72%\n",
      "iter 1800: loss 0.1867, time 230.96ms, mfu 2.75%\n",
      "iter 1850: loss 0.2345, time 226.86ms, mfu 2.78%\n",
      "iter 1900: loss 0.1747, time 225.78ms, mfu 2.80%\n",
      "iter 1950: loss 0.1729, time 229.49ms, mfu 2.82%\n",
      "step 2000: train loss 0.1663, val loss 9.5471\n",
      "iter 2000: loss 0.1700, time 4944.24ms, mfu 2.55%\n",
      "iter 2050: loss 0.1583, time 231.36ms, mfu 2.60%\n",
      "iter 2100: loss 0.1342, time 232.42ms, mfu 2.63%\n",
      "iter 2150: loss 0.1902, time 232.43ms, mfu 2.66%\n",
      "iter 2200: loss 0.1629, time 234.91ms, mfu 2.69%\n",
      "iter 2250: loss 0.1314, time 230.40ms, mfu 2.72%\n",
      "iter 2300: loss 0.1236, time 229.63ms, mfu 2.75%\n",
      "iter 2350: loss 0.1689, time 232.03ms, mfu 2.77%\n",
      "iter 2400: loss 0.1478, time 230.03ms, mfu 2.79%\n",
      "iter 2450: loss 0.1088, time 232.21ms, mfu 2.81%\n",
      "step 2500: train loss 0.1417, val loss 9.8520\n",
      "iter 2500: loss 0.1337, time 4906.07ms, mfu 2.54%\n",
      "iter 2550: loss 0.1540, time 234.48ms, mfu 2.58%\n",
      "iter 2600: loss 0.1619, time 231.33ms, mfu 2.62%\n",
      "iter 2650: loss 0.1461, time 232.25ms, mfu 2.65%\n",
      "iter 2700: loss 0.1137, time 233.41ms, mfu 2.68%\n",
      "iter 2750: loss 0.1163, time 231.16ms, mfu 2.71%\n",
      "iter 2800: loss 0.1321, time 232.86ms, mfu 2.73%\n",
      "iter 2850: loss 0.1317, time 229.67ms, mfu 2.76%\n",
      "iter 2900: loss 0.1052, time 232.18ms, mfu 2.78%\n",
      "iter 2950: loss 0.1334, time 230.74ms, mfu 2.80%\n",
      "step 3000: train loss 0.1254, val loss 10.0470\n",
      "iter 3000: loss 0.1126, time 4948.63ms, mfu 2.53%\n",
      "iter 3050: loss 0.1501, time 233.74ms, mfu 2.57%\n",
      "iter 3100: loss 0.1404, time 229.98ms, mfu 2.61%\n",
      "iter 3150: loss 0.1646, time 226.93ms, mfu 2.66%\n",
      "iter 3200: loss 0.1386, time 232.11ms, mfu 2.69%\n",
      "iter 3250: loss 0.1448, time 229.93ms, mfu 2.72%\n",
      "iter 3300: loss 0.1358, time 226.76ms, mfu 2.75%\n",
      "iter 3350: loss 0.1121, time 230.85ms, mfu 2.77%\n",
      "iter 3400: loss 0.0936, time 232.72ms, mfu 2.79%\n",
      "iter 3450: loss 0.1061, time 229.94ms, mfu 2.81%\n",
      "step 3500: train loss 0.1165, val loss 10.3808\n",
      "iter 3500: loss 0.0910, time 4909.35ms, mfu 2.54%\n",
      "iter 3550: loss 0.1183, time 233.22ms, mfu 2.58%\n",
      "iter 3600: loss 0.1178, time 226.53ms, mfu 2.63%\n",
      "iter 3650: loss 0.1030, time 228.26ms, mfu 2.66%\n",
      "iter 3700: loss 0.1005, time 225.04ms, mfu 2.70%\n",
      "iter 3750: loss 0.0980, time 229.77ms, mfu 2.73%\n",
      "iter 3800: loss 0.1073, time 230.46ms, mfu 2.76%\n",
      "iter 3850: loss 0.0975, time 232.44ms, mfu 2.78%\n",
      "iter 3900: loss 0.0818, time 231.64ms, mfu 2.80%\n",
      "iter 3950: loss 0.1220, time 228.48ms, mfu 2.82%\n",
      "step 4000: train loss 0.1019, val loss 10.5375\n",
      "iter 4000: loss 0.0958, time 4945.01ms, mfu 2.55%\n",
      "iter 4050: loss 0.0932, time 232.06ms, mfu 2.59%\n",
      "iter 4100: loss 0.0963, time 230.57ms, mfu 2.63%\n",
      "iter 4150: loss 0.1062, time 226.51ms, mfu 2.67%\n",
      "iter 4200: loss 0.1076, time 226.24ms, mfu 2.71%\n",
      "iter 4250: loss 0.0815, time 228.45ms, mfu 2.74%\n",
      "iter 4300: loss 0.0721, time 234.45ms, mfu 2.76%\n",
      "iter 4350: loss 0.0942, time 235.49ms, mfu 2.77%\n",
      "iter 4400: loss 0.1058, time 226.26ms, mfu 2.80%\n",
      "iter 4450: loss 0.0879, time 230.61ms, mfu 2.82%\n",
      "step 4500: train loss 0.0927, val loss 10.6742\n",
      "iter 4500: loss 0.0918, time 4925.01ms, mfu 2.55%\n",
      "iter 4550: loss 0.0891, time 232.54ms, mfu 2.59%\n",
      "iter 4600: loss 0.1003, time 229.70ms, mfu 2.63%\n",
      "iter 4650: loss 0.0821, time 226.47ms, mfu 2.67%\n",
      "iter 4700: loss 0.0926, time 226.01ms, mfu 2.71%\n",
      "iter 4750: loss 0.0729, time 230.21ms, mfu 2.73%\n",
      "iter 4800: loss 0.0878, time 230.43ms, mfu 2.76%\n",
      "iter 4850: loss 0.0674, time 233.07ms, mfu 2.78%\n",
      "iter 4900: loss 0.0924, time 232.67ms, mfu 2.79%\n",
      "iter 4950: loss 0.1131, time 230.91ms, mfu 2.81%\n",
      "step 5000: train loss 0.0856, val loss 10.6805\n",
      "iter 5000: loss 0.0759, time 4938.64ms, mfu 2.55%\n",
      "iter 5050: loss 0.0727, time 231.02ms, mfu 2.59%\n",
      "iter 5100: loss 0.0760, time 233.44ms, mfu 2.62%\n",
      "iter 5150: loss 0.0846, time 229.63ms, mfu 2.66%\n",
      "iter 5200: loss 0.0935, time 228.62ms, mfu 2.69%\n",
      "iter 5250: loss 0.0728, time 231.48ms, mfu 2.72%\n",
      "iter 5300: loss 0.0735, time 229.50ms, mfu 2.75%\n",
      "iter 5350: loss 0.0892, time 228.44ms, mfu 2.77%\n",
      "iter 5400: loss 0.0960, time 231.65ms, mfu 2.79%\n",
      "iter 5450: loss 0.0766, time 230.34ms, mfu 2.81%\n",
      "step 5500: train loss 0.0757, val loss 10.8102\n",
      "iter 5500: loss 0.0639, time 4914.61ms, mfu 2.55%\n",
      "iter 5550: loss 0.0703, time 231.03ms, mfu 2.59%\n",
      "iter 5600: loss 0.0772, time 225.88ms, mfu 2.63%\n",
      "iter 5650: loss 0.0790, time 233.07ms, mfu 2.66%\n",
      "iter 5700: loss 0.0669, time 227.14ms, mfu 2.70%\n",
      "iter 5750: loss 0.0783, time 230.61ms, mfu 2.73%\n",
      "iter 5800: loss 0.0816, time 232.99ms, mfu 2.75%\n",
      "iter 5850: loss 0.0850, time 232.34ms, mfu 2.77%\n",
      "iter 5900: loss 0.0721, time 230.98ms, mfu 2.79%\n",
      "iter 5950: loss 0.0607, time 226.75ms, mfu 2.81%\n",
      "step 6000: train loss 0.0707, val loss 10.8630\n",
      "iter 6000: loss 0.0693, time 4930.32ms, mfu 2.55%\n",
      "iter 6050: loss 0.0547, time 229.24ms, mfu 2.59%\n",
      "iter 6100: loss 0.0638, time 233.29ms, mfu 2.63%\n",
      "iter 6150: loss 0.0638, time 229.90ms, mfu 2.66%\n",
      "iter 6200: loss 0.0693, time 229.07ms, mfu 2.70%\n",
      "iter 6250: loss 0.0689, time 230.99ms, mfu 2.72%\n",
      "iter 6300: loss 0.0441, time 225.55ms, mfu 2.76%\n",
      "iter 6350: loss 0.0758, time 226.53ms, mfu 2.78%\n",
      "iter 6400: loss 0.0714, time 231.33ms, mfu 2.80%\n",
      "iter 6450: loss 0.0682, time 230.62ms, mfu 2.82%\n",
      "step 6500: train loss 0.0655, val loss 10.7886\n",
      "iter 6500: loss 0.0675, time 4903.33ms, mfu 2.55%\n",
      "iter 6550: loss 0.0674, time 231.68ms, mfu 2.59%\n",
      "iter 6600: loss 0.0650, time 225.81ms, mfu 2.64%\n",
      "iter 6650: loss 0.0769, time 231.24ms, mfu 2.67%\n",
      "iter 6700: loss 0.0504, time 231.18ms, mfu 2.70%\n",
      "iter 6750: loss 0.0640, time 231.79ms, mfu 2.73%\n",
      "iter 6800: loss 0.0548, time 232.51ms, mfu 2.75%\n",
      "iter 6850: loss 0.0663, time 233.18ms, mfu 2.77%\n",
      "iter 6900: loss 0.0662, time 229.75ms, mfu 2.79%\n",
      "iter 6950: loss 0.0556, time 232.44ms, mfu 2.81%\n",
      "step 7000: train loss 0.0617, val loss 10.7669\n",
      "iter 7000: loss 0.0627, time 4923.02ms, mfu 2.54%\n",
      "iter 7050: loss 0.0548, time 231.97ms, mfu 2.58%\n",
      "iter 7100: loss 0.0660, time 229.30ms, mfu 2.62%\n",
      "iter 7150: loss 0.0592, time 234.75ms, mfu 2.65%\n",
      "iter 7200: loss 0.0531, time 227.78ms, mfu 2.69%\n",
      "iter 7250: loss 0.0487, time 231.49ms, mfu 2.72%\n",
      "iter 7300: loss 0.0501, time 234.72ms, mfu 2.74%\n",
      "iter 7350: loss 0.0539, time 229.98ms, mfu 2.76%\n",
      "iter 7400: loss 0.0573, time 232.80ms, mfu 2.78%\n",
      "iter 7450: loss 0.0581, time 234.07ms, mfu 2.80%\n",
      "step 7500: train loss 0.0578, val loss 10.7529\n",
      "iter 7500: loss 0.0668, time 4890.88ms, mfu 2.53%\n",
      "iter 7550: loss 0.0510, time 230.77ms, mfu 2.58%\n",
      "iter 7600: loss 0.0521, time 229.31ms, mfu 2.62%\n",
      "iter 7650: loss 0.0425, time 231.02ms, mfu 2.65%\n",
      "iter 7700: loss 0.0539, time 228.77ms, mfu 2.69%\n",
      "iter 7750: loss 0.0573, time 226.06ms, mfu 2.72%\n",
      "iter 7800: loss 0.0510, time 232.06ms, mfu 2.75%\n",
      "iter 7850: loss 0.0655, time 233.11ms, mfu 2.77%\n",
      "iter 7900: loss 0.0610, time 225.23ms, mfu 2.80%\n",
      "iter 7950: loss 0.0570, time 228.19ms, mfu 2.82%\n",
      "step 8000: train loss 0.0533, val loss 10.8232\n",
      "iter 8000: loss 0.0485, time 4941.74ms, mfu 2.55%\n",
      "iter 8050: loss 0.0700, time 229.36ms, mfu 2.59%\n",
      "iter 8100: loss 0.0406, time 226.01ms, mfu 2.64%\n",
      "iter 8150: loss 0.0497, time 230.51ms, mfu 2.67%\n",
      "iter 8200: loss 0.0592, time 225.70ms, mfu 2.71%\n",
      "iter 8250: loss 0.0577, time 228.01ms, mfu 2.74%\n",
      "iter 8300: loss 0.0476, time 228.43ms, mfu 2.77%\n",
      "iter 8350: loss 0.0409, time 234.16ms, mfu 2.78%\n",
      "iter 8400: loss 0.0432, time 233.95ms, mfu 2.80%\n",
      "iter 8450: loss 0.0554, time 230.37ms, mfu 2.82%\n",
      "step 8500: train loss 0.0511, val loss 10.6289\n",
      "iter 8500: loss 0.0558, time 4896.98ms, mfu 2.55%\n",
      "iter 8550: loss 0.0585, time 233.66ms, mfu 2.59%\n",
      "iter 8600: loss 0.0440, time 231.39ms, mfu 2.63%\n",
      "iter 8650: loss 0.0548, time 227.43ms, mfu 2.67%\n",
      "iter 8700: loss 0.0548, time 233.41ms, mfu 2.69%\n",
      "iter 8750: loss 0.0585, time 230.81ms, mfu 2.72%\n",
      "iter 8800: loss 0.0480, time 229.93ms, mfu 2.75%\n",
      "iter 8850: loss 0.0470, time 233.50ms, mfu 2.77%\n",
      "iter 8900: loss 0.0492, time 232.17ms, mfu 2.79%\n",
      "iter 8950: loss 0.0467, time 227.28ms, mfu 2.81%\n",
      "step 9000: train loss 0.0485, val loss 10.7615\n",
      "iter 9000: loss 0.0520, time 4924.83ms, mfu 2.54%\n",
      "iter 9050: loss 0.0464, time 232.05ms, mfu 2.58%\n",
      "iter 9100: loss 0.0282, time 232.74ms, mfu 2.62%\n",
      "iter 9150: loss 0.0472, time 226.36ms, mfu 2.66%\n",
      "iter 9200: loss 0.0550, time 227.88ms, mfu 2.70%\n",
      "iter 9250: loss 0.0452, time 229.94ms, mfu 2.73%\n",
      "iter 9300: loss 0.0435, time 228.58ms, mfu 2.75%\n",
      "iter 9350: loss 0.0559, time 232.71ms, mfu 2.77%\n",
      "iter 9400: loss 0.0474, time 228.74ms, mfu 2.80%\n",
      "iter 9450: loss 0.0358, time 234.43ms, mfu 2.81%\n",
      "step 9500: train loss 0.0472, val loss 10.6653\n",
      "iter 9500: loss 0.0445, time 4891.50ms, mfu 2.54%\n",
      "iter 9550: loss 0.0493, time 228.49ms, mfu 2.59%\n",
      "iter 9600: loss 0.0448, time 228.44ms, mfu 2.63%\n",
      "iter 9650: loss 0.0451, time 233.10ms, mfu 2.66%\n",
      "iter 9700: loss 0.0396, time 230.32ms, mfu 2.69%\n",
      "iter 9750: loss 0.0514, time 226.01ms, mfu 2.73%\n",
      "iter 9800: loss 0.0412, time 229.68ms, mfu 2.76%\n",
      "iter 9850: loss 0.0505, time 229.24ms, mfu 2.78%\n",
      "iter 9900: loss 0.0452, time 228.77ms, mfu 2.80%\n",
      "iter 9950: loss 0.0589, time 227.44ms, mfu 2.82%\n",
      "step 10000: train loss 0.0449, val loss 10.5694\n",
      "iter 10000: loss 0.0393, time 4914.80ms, mfu 2.55%\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "! torchrun --standalone --nproc_per_node=2 train_1_layer_att.py",
   "id": "698893b71fc67a20"
  },
  {
   "cell_type": "code",
   "source": [
    "! python sample_mingpt.py"
   ],
   "metadata": {
    "id": "GTCLUHXWSsqV",
    "outputId": "c2797d5e-5bbe-470e-a448-e97eb3986295",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "GTCLUHXWSsqV",
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "number of parameters: 22.86M\n",
      "No meta.pkl found, assuming GPT-2 encodings...\n",
      "\n",
      "That any means, yet to use it is your children;\n",
      "But in that I may weep to murder her grave.\n",
      "Lady, madam?\n",
      "\n",
      "QUEEN:\n",
      "So I should her, and do,\n",
      "Yet none of you know, madam: yet,\n",
      "The supreme of any of these no further,\n",
      "Nor none of this land do permit: the people;\n",
      "For then that, I mightily stole away!'\n",
      "Yes, and thrive I of our King Richard's guard\n",
      "That we from the nobility should have heard\n",
      "That ever perceive\n",
      "Hath been with their teeth clean.\n",
      "\n",
      "RATCLIFF:\n",
      "Good mother, the deep as I beg of him?\n",
      "\n",
      "RIVERS:\n",
      "Dolling to a loins out of a truth;\n",
      "And bid my dear lord: O, thou hast said,\n",
      "To whom to no further death or thy mother,\n",
      "For ever grace are abused.\n",
      "\n",
      "LADY ANNE:\n",
      "By this man by their lives a traitor's blood.\n",
      "\n",
      "GLOUCESTER:\n",
      "Upon his face is, when princely lay;\n",
      "Thy son was the house of Lancaster.\n",
      "Wert thou a traitor'st, Duke of York.\n",
      "\n",
      "RIVERS:\n",
      "What, Richard's the king'd??\n",
      "\n",
      "GLOUCESTER:\n",
      "He shall the king that did forgot the king?\n",
      "\n",
      "RIVERS:\n",
      "No, by, no doubt, God give: I do you thanks.\n",
      "\n",
      "GLOUCESTER:\n",
      "The dangerous honour is this frail.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "What be so far as I fly?\n",
      "\n",
      "BUCKINGHAM:\n",
      "Long live Edward is the mayor of the seas?\n",
      "\n",
      "GLOUCESTER:\n",
      "Brother of France? take our defence.\n",
      "\n",
      "CLARENCE:\n",
      "O, farewell; and willingly rise and have.\n",
      "\n",
      "KING EDWARD IV:\n",
      "And then, you canst thou yield both.\n",
      "\n",
      "LADY GREY:\n",
      "Ay, then, then, but see them in a pitchy battle; and therefore shall meet.\n",
      "\n",
      "KING EDWARD IV:\n",
      "No, then I will not forlars.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Yes, but we will, for men.\n",
      "And then, in the better means revengeful Edward'st thou,\n",
      "Will never send; for I\n",
      "---------------\n",
      "\n",
      "\n",
      "GLOUCESTER:\n",
      "The king, why stand you bowels and your best?\n",
      "\n",
      "LADY ANNE:\n",
      "Why, then, if us a long live?\n",
      "\n",
      "GLOUCESTER:\n",
      "Thou mightst be blest, like a Christian land\n",
      "And give them wrong, becauseal,\n",
      "For far off again.\n",
      "\n",
      "LADY ANNE:\n",
      "Why do I last night, then was dead?\n",
      "\n",
      "GLOUCESTER:\n",
      "Marry, then, then, for thee swear;\n",
      "I was not with a woman, but they were dead.\n",
      "\n",
      "GLOUCESTER:\n",
      "He means that were flatter'd his.\n",
      "\n",
      "LADY ANNE:\n",
      "I might current and, no.\n",
      "\n",
      "GLOUCESTER:\n",
      "I was to kill myself.\n",
      "\n",
      "Y ANNE:\n",
      "I would they had saved so profeseeming and myself a king;\n",
      "For how my dear a traitor to do?\n",
      "As being so foul and urged, is,\n",
      "And these time I the doth hold of a fool.\n",
      "\n",
      "GLOUCESTER:\n",
      "Made him a traitor, Lord of his majesty'Yea, and his head;\n",
      "The kites and defiled him!\n",
      "Speakethinks I speak for whose circuit is sending overta'en to go with form\n",
      "To rest before I live, like two days before we.\n",
      "3 KING HENRY VI\n",
      "\n",
      "RIVERS:\n",
      "Give me my good comfort with Margaret, farewell.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "My soul, my happy days'Tis needful soul: go with you!\n",
      "\n",
      "YORK:\n",
      "She comes,--\n",
      "\n",
      "GLOUCESTER:\n",
      "Ay, and, but a pitchy news too sudden! and we may be buried.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Ay, then, to tell;\n",
      "But Edward is the king that'st thou but already.\n",
      "\n",
      "GLOUCESTER:\n",
      "'Twere Darest Clarence, what news of Clarence, and forget\n",
      "I do they of York, and I do so.\n",
      "\n",
      "CLARENCE:\n",
      "When I have heard?\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Ay, but think'st thou! would I have music.\n",
      "For, but then I stabb'd with words, my dear York\n",
      "---------------\n",
      "\n",
      "\n",
      "LADY ANNE:\n",
      "'Tis more, no.\n",
      "\n",
      "GLOUCESTER:\n",
      "Why, so.\n",
      "\n",
      "LADY ANNE:\n",
      "Why, then he is a subject as true.\n",
      "\n",
      "GLOUCESTER:\n",
      "Thy side, by thy foul misdoubt not;\n",
      "I not; here stands with most quickly.\n",
      "\n",
      "DORSET:\n",
      "No, but vex him. My dear my soul is the souls of England;\n",
      "The sacred honour is uneven and merit practise.\n",
      "\n",
      "My lord hurt your grace hath done.\n",
      "\n",
      "WARWICK:\n",
      "Is not a traitor to fly:\n",
      "I think is left to part,\n",
      "For thou wert thou as a traitor to fight:\n",
      "And as we have too dreadful sway,\n",
      "Cry 't but 'tisBRUTUS:\n",
      "Oly father unto the state,\n",
      "'Twas, and kneel before his truth:\n",
      "What, belike was your your enemies?\n",
      "\n",
      "LORD ROSS:\n",
      "Have done to you forgot; his majesty\n",
      "He hath not that never free.\n",
      "\n",
      "NORTHUMBERLAND:\n",
      "His son is not seen to make, are his majesty\n",
      "To seek that never then; for I must have,\n",
      "I speak, to hold upon; yet there no good.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Then give leave you pardon me leave, my tongue\n",
      "Pale being thus; nay, men's pardon, if either,\n",
      "Should live be not so, the:\n",
      "Makes my glazed on my cousin, and paper.\n",
      "And with growing with, and thou, have'st,\n",
      "By this rude, are gone to wash away the breath;\n",
      "And yet thou diadem.\n",
      "Edward's Richard:'\n",
      "Edward take the ground, though I be my father,\n",
      "And wring from his sake, then remain with our hands,\n",
      "And seize Hereford's nest, where; and let's beat me!\n",
      "\n",
      "KING RICHARD II:\n",
      "O Richard, how do not pass'd, who began it so ill!\n",
      "\n",
      "God send him so long and my life?\n",
      "\n",
      "ARCHBISHOP OF YORK:\n",
      "What is this new news?\n",
      "\n",
      "RIVERS:\n",
      "Hadst thou done so much unto think'st thou but a knightly king.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "\n",
      "---------------\n",
      "\n",
      "\n",
      "LADY GREY:\n",
      "But when I had forgot myself.\n",
      "\n",
      "KING EDWARD IV:\n",
      "What widow's lands both? the strength of death?\n",
      "\n",
      "LADY GREY:\n",
      "My need to take my liege.\n",
      "\n",
      "LADY:\n",
      "What is your grace?\n",
      "KING EDWARD IV:\n",
      "So long I have, but to keep your husband.\n",
      "\n",
      "LADY GREY:\n",
      "Why, then! offer is to himself over-night\n",
      "\n",
      "KING EDWARD IV:\n",
      "The high but by right.\n",
      "LADY GREY:\n",
      "Then bid me prove a subject is.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Shall quondam king, I spake with your husband.\n",
      "\n",
      "LADY:\n",
      "Then merry, I for yet to a king.\n",
      "\n",
      "GLOUCESTER:\n",
      "\n",
      "LADY GREY:\n",
      "Why should you then.\n",
      "\n",
      "KING EDWARD IV:\n",
      "No, then, then I see them so.\n",
      "\n",
      "LADY GREY:\n",
      "No, my lord; I will take my leave behind unto:\n",
      "I'll try these lands I'll bring him as you.\n",
      "\n",
      "LADY GREY:\n",
      "Ay, full as you's many years.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Why, then I'll call you then.\n",
      "\n",
      "LADY GREY:\n",
      "So would you love 'tis my young and hear my husband.\n",
      "\n",
      "KING EDWARD IV:\n",
      "No, then that you mistake am I to draw your queen;\n",
      "To use that, and use it, though to be tempted.\n",
      "What, if thou be valiant dost thou know'st, where.\n",
      "\n",
      "LADY ANNE:\n",
      "What, who dost thou believe thee, who hath not been by?\n",
      "\n",
      "GLOUCESTER:\n",
      "'Tis so fast?\n",
      "\n",
      "LADY ANNE:\n",
      "Naught! why, they are, look out to stay these articles.\n",
      "\n",
      "\n",
      "KING EDWARD IV:\n",
      "And, I speak from the world these news, then,\n",
      "Tell them how now, I will come to die.\n",
      "\n",
      "CLARENCE:\n",
      "Would well, what news?\n",
      "\n",
      "GLOUCESTER:\n",
      "With slow and fly there, God forbid their hands?\n",
      "\n",
      "LADY ANNE:\n",
      "He cannot live already! for now appeal a\n",
      "---------------\n",
      "\n",
      "' it's a day for some glorious seen.\n",
      "O, revenge it is sworn to that extremity\n",
      "When time make my best tongue\n",
      "Hath mistaking sleep as lark, girl;\n",
      "Or how came it is it a dead.\n",
      "\n",
      "ROMEO:\n",
      "A spider on thy woful sympathy,\n",
      "And yonder blessed were as liest heavy!\n",
      "Where that I shall grief pound and weeping hence so I,\n",
      "Where vial of our lights up the light as I shall back\n",
      "Hath made her light throughly violence on her light;\n",
      "But that I, like you this night.\n",
      "Hath she, like a while the light is dead;\n",
      "But that she, for I, like a fair,\n",
      "The queen of Clarence shall she as she be, love, was gone;\n",
      "And now bad subject as true Edward's spirit, for prophecies\n",
      "And from the cross-favour'd and dreams?\n",
      "And from the cross-fiful.\n",
      "And, Richard, Richard with a July's night day day.\n",
      "\n",
      "JULIET:\n",
      "Live, with her and in post, with his forfeit doves day.\n",
      "If God-night, all the arm of the prince,\n",
      "And with her and fortune, with his fortune of the world\n",
      ":\n",
      "And with a pitch his several steel.\n",
      "\n",
      "BUCKINGHAM:\n",
      "My lord, I shall meet me with me straight:\n",
      "Richard, I took this is prayer upon now:\n",
      "Therefore, give give leave his head, no sign of love.\n",
      "\n",
      "HASTINGS:\n",
      "I'll, if you tell thee honour--th well, and give my heart in mind\n",
      "In woful than take it publicly,\n",
      "So live, so dishoniberio. Farewell.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Well, well ta'Tut, we tell we read.\n",
      "\n",
      "HASTINGS:\n",
      "So soon not so I go, well then, to be gone.\n",
      "I'Tis better witness good noble Hastings wits.\n",
      "\n",
      "HASTINGS:\n",
      "Ay, and to stand high fortune.\n",
      "\n",
      "GLOUCESTER:\n",
      "I thank your grace.\n",
      "Come, cousin Buckingham, bring forth to our good day unto your royal presence;\n",
      "And joys may appear too hard as I shall repossips for your first\n",
      "Is it to him as much.\n",
      "\n",
      "HASTINGS:\n",
      "What is\n",
      "---------------\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
